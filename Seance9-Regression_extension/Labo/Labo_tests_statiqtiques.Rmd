---
title: 'Test statistiques'
author: "Visseho Adjiwanou, PhD."
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document: default
  word_document: default
  html_document: default
---


# Question 1

Supposons que vous ayez deux groupes d'étudiants, un groupe de majors en mathématiques et un groupe de majors en philosophie. Vous voulez en savoir plus sur leurs capacités de pensée critique. Vous demandez à chaque groupe de passer un test. Les résultats montrent que les 28 étudiants en majors en mathématiques ont en moyenne un score de 88 avec un écart type de 6 et que les 19 étudiants en majors en philosophie ont en moyenne un score de 90 avec un écart type de 3. Utilisez ces informations pour déterminer ce qui suit:

1. Quelles sont les variables à l'étude
2. Si vous voulez faire une régression, comment allez vous le faire?
3. Énoncer votre hypothèse nulle
4. La différence entre les majors en mathématiques et les majors en philosophie est-elle statistiquement significative au niveau de signification de 1%? Expliquer. Que dire de 5%?


## Solution

### 1. Quelles sont les variables à l'étude

Combien de variable avons-nous?

variable 1: domaine d'études (math ou philo), qualitative, nominale, dichotomique
variable 2: score obtenu, quantitative, ratio, continue

On ne peut pas utiliser le test de chi-carré

Mais, si on tient à utiliser le chi-carré, que doit-on faire?


### 2. Si vous voulez faire une régression, comment allez vous le faire?


Soit 
- Yi le score obtenu par l'étudiant i
- Xi le domaine d'études de l'étudiant i

$$Score_i = \beta_0 + \beta_1DomaineEtude + \epsilon_i$$

Mieux, on va écrire ce modèle comme:
$$Score_i = \beta_0 + \beta_1Math + \epsilon_i$$
Puisque nous savons que la variable Domaine d'étude ne prend que deux valeurs.

Ce que nous voulons tester est alors $$\beta_1 = 0$$

## 3. Énoncer votre hypothèse nulle



H0: Il n'y a pas de différence entre les capacités de pensée critique entre ceux qui font une majeure en mathématique et ceux qui font une majeure en philosophie (en termes statistiques, le score moyen chez les mathématiciens = score moyen chez les philosophes)

H0 : $$\mu_{philo} = \mu_{math}$$ ou

H0 : $$\mu_{philo} - \mu_{math} = 0$$


## 4. Test statistiques

Sous l'hypothèse nulle, $\mu_1 - \mu_2 = 0$, la statistique $$t = \frac{\bar{X}_1 - \bar{X}_2}{s_{\bar{X}_1 - \bar{X}_2}}$$ suit une loi de Student à $(n_1-1) + (n_2 -1)$ degrés de liberté.


- Regardons à quoi ressemble la distribution de Students comparativement à la distribution normale

```{r}

library(tidyverse)

ggplot(data = data.frame(t = c(-4, 4)), aes(t)) +
  stat_function(fun = dt, args = list(df = 5)) +
  stat_function(fun = dnorm, color = "red")
                
```

- Influence du degré de liberté


```{r}

ggplot(data = data.frame(t = c(-4, 4)), aes(t)) +
  stat_function(fun = dt, args = list(df = 5)) +
  stat_function(fun = dt, args = list(df = 2), color = "blue") +
  stat_function(fun = dt, args = list(df = 1), color = "green") 
                
```

Et donc la décision de votre test statistique va dépendre forcément du nombre de degré de liberté, autrement dit, de la taille de l'échantillon.

- Calculons t

a. dénominateur: erreur type de la différence entre les moyennes


la formule de l'erreur-type de la différence de moyenne vaut:

$$s_{\bar{X}_1 - \bar{X}_2} = \sqrt{(\frac{N_1*s_1^2 + N_2*s_2^2}{N_1 + N_2 - 2})(\frac{N_1 + N_2}{N_1*N_2})}$$

Calculons cela:

```{r}

# Groupe des maths

N1 <- 28
s1_carre <- 6^2

# Groupe des philosophes

N2 <- 19
s2_carre <- 3^2

# Calcul de l'erreur par étape

## Numérateur fraction 1

nf1 <- N1*s1_carre + N2*s2_carre

## denominateur fraction 1

df1 <- N1 + N2 - 2

f1 <- nf1/df1

## Numérateur et denominateur fraction 2

nf2 <- N1 + N2
df2 <- N1*N2

f2 <- nf2/df2

## Erreur-type

s12 <- sqrt(f1*f2)
s12

```


b. Numérateur 

```{r}
X1_bar <- 88
X2_bar <- 90

diff_X1X2 <- X1_bar - X2_bar
diff_X1X2

```


c. La statistique t


$$t = \frac{\bar{X}_1 - \bar{X}_2}{s_{\bar{X}_1 - \bar{X}_2}}$$

```{r}


t_calcule <- diff_X1X2/s12
t_calcule

```


d. degré de liberté

degré de liberté = 28 + 19 - 2  = 45


e. t lu

t lu = 2.704 (avec la table de distribution de la loi de Student) 
On est conservateur en prenant 40 degrés de liberté.

niveau de signification de 1%

```{r}
knitr::include_graphics("../Images/Table_Student.png")
```



Vous pouvez aussi le calculer de cette manière:


```{r}

t_lu <- qt(0.005, df=45)
t_lu
# qnorm(0.005)

```

La vraie valeur vaut:


t_lu: 0.005% de la distribution ont une valeur inférieur à la valeur trouvée


f. Décision

t calculé en valeur absolu = 1.31 < t lu = 2.704, on **ne peut pas rejeter** l'hypothèse nulle. Autrement dit, il n'existe pas d'association significative entre le domaine de formation et la capacité de raisonnement critique.


## Utilisation de l'intervalle de confiance

On peut aboutir aux mêmes résultats en utilisant l'intervalle de confiance.

La formule de l'intervalle de confiance est:

$$IC = (\bar{X_1} - \bar{X_2}) ± t_{\text{seuil choisi}}*s_{\bar{X_1} - \bar{X_2}}$$
On connait déjà :
1. $\bar{X_1} - \bar{X_2}$
2. $s_{\bar{X_1} - \bar{X_2}}$ et 
3 le t lu.

Si cette intervalle de confiance contient 0, on ne peut pas rejeter l'hypothèse nulle.


Voici la distribution de la différence des deux moyennes avec le degré de liberté de 45

```{r}


dist_t <- ggplot(data = data.frame(t = c(-4, 4)), aes(t)) +
  stat_function(fun = dt, args = list(df = 5), color = "red") +
  stat_function(fun = dt, args = list(df = 5), color = "green") +
  stat_function(fun = dt, args = list(df = 150), color = "blue")

dist_t

```

Je cherche les valeurs de t pour lesquelles 99% de la distribution se trouve à l'intérieur de cette valeur.


```{r}

ggplot(data = data.frame(x = c(-4, 4)), aes(x)) +
  stat_function(fun = dt, args = list(df = 45), color = "red") +
  stat_function(fun = dt, args = list(df = 45), color = "red",
                geom = "area", fill = "lightblue",
                xlim = c(-4, 1.7))   

```

On n'a ainsi 99,5% de la distribution qui se trouve dans la zone bleue.

De même, ici, on 0,5% de la distribution qui se trouve dans la zone verte.

```{r}

ggplot(data = data.frame(x = c(-4, 4)), aes(x)) +
  stat_function(fun = dt, args = list(df = 45), color = "red") +
  stat_function(fun = dt, args = list(df = 45), color = "red",
                geom = "area", fill = "green",
                xlim = c(-4, -1.7))  

```

Nous pouvons alors déduire que 99% de la distribution se trouve ici:

```{r}

ggplot(data = data.frame(x = c(-4, 4)), aes(x)) +
  stat_function(fun = dt, args = list(df = 45), color = "red") +
  stat_function(fun = dt, args = list(df = 45), color = "red",
                geom = "area", fill = "purple", alpha = 0.2,
                xlim = c(-1.7, 1.7)) 

```

Maintenant, trouvons les vraies valeurs des quantiles

Au seuil de 1%

```{r}

qt(0.5, df = 45)

bi <- qt(0.005, df=45)
bi

bs <- qt(0.995, df=45)
bi
bs

```

Voici le graphique qui vous donne les quantiles :

bi: 0.5% de la distribution ont une valeur inférieur à la valeur trouvée
bs: 99.5% de la distribution ont une valeur supérieure à la valeur trouvée

Ainsi, on peut dire que 99% de la distribution ont une valeur comprise entre bi et bs.
Avec notre niveau de signification de 1%, notre t devrait être à l'extérieur de cette zone.


Exécuter ce code une ligne à la fois, et vous verrez comment c'est crée.

Quelles sont les différents graphiques qui sont créés et avec quelle fonction?

```{r}

df <- N1 + N2 -2
df

acceptation_rejet <-
  ggplot(data = data.frame(t = c(-4, 4)), aes(t)) +
  stat_function(fun = dt, args = list(df = 45), color = "red") +
  geom_vline(aes(xintercept = bi), color = "blue") +
  geom_vline(aes(xintercept = bs), color = "green") +
  geom_segment(aes(x = bi, xend = bs, y = 0, yend = 0), 
               arrow = arrow(length = unit(0.1,"cm"), ends = "both"), 
               color = "black") +
  stat_function(fun = dt, args = list(df = 45),
                xlim = c(bs, 4),
                geom = "area", fill = "lightblue") +
  stat_function(fun = dt, args = list(df = 45),
                xlim = c(-4, bi),
                geom = "area", fill = "lightblue") +
  stat_function(fun = dt, args = list(df = 45),
                xlim = c(bi, bs),
                geom = "area", fill = "purple", alpha = 0.2) +
  geom_abline(aes(slope = 0, intercept = -1.314578), color = "black")+
  theme(legend.position = "none")

acceptation_rejet

?geom_abline
```



La fonction pour tracer la ligne était juste devant moi. J'avais déjà tracé deux lignes avec la fonction vline. La fonction geom_abline vous permet de tracer aussi des droites mais de manière générale. vline pour dire **vertical line**.


```{r}

t_calcule <- 1.314578

acceptation_rejet <-
  ggplot(data = data.frame(t = c(-4, 4)), aes(t)) +
  stat_function(fun = dt, args = list(df = 45), color = "red") +
  geom_vline(aes(xintercept = bi), color = "blue") +
  geom_vline(aes(xintercept = bs), color = "green") +
  geom_segment(aes(x = bi, xend = bs, y = 0, yend = 0), 
               arrow = arrow(length = unit(0.1,"cm"), ends = "both"), 
               color = "black") +
  stat_function(fun = dt, args = list(df = 45),
                xlim = c(bs, 4),
                geom = "area", fill = "lightblue") +
  stat_function(fun = dt, args = list(df = 45),
                xlim = c(-4, bi),
                geom = "area", fill = "lightblue") +
  stat_function(fun = dt, args = list(df = 45),
                xlim = c(bi, bs),
                geom = "area", fill = "purple", alpha = 0.2) +
  geom_vline(aes(xintercept = t_calcule), color = "black")+
  theme(legend.position = "none")

acceptation_rejet

```

On voit dont que cela se trouve bien dans la zone mauve.


- Refaites la même chose, cette fois-ci avec un niveau de signification de 5%. Quelle conclusion vous-tirez?


# Les autres distributions

- Fisher 

```{r}

ggplot(data.frame(x = c(0, 5)), aes(x)) +
  stat_function(fun = df,
                geom = "area",
                fill = "steelblue",
                args = list(
                  df1 = 3,
                  df2 = 47
                ))
```

```{r}

qt()

qf(0.95, df1 = 4, df2 = 7)

```

